{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/dmlc/dgl/blob/master/examples/pytorch/gat/train.py\n",
    "#节点分类：临近节点属性替换该节点\n",
    "#边 ： 不能用临近节点属性替换\n",
    "#所有值都是数值型：字符转成哑变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_preprocessing.ipynb', 'pyg_autoencoder.ipynb', 'dgl_gcn_example.ipynb', 'DGL_GCN.ipynb', 'DGL_GAT_demo.ipynb', 'NOTE.txt', 'DGL_GAT.ipynb', '.ipynb_checkpoints', 'data', 'pyg_autoencoder_example.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir = \"../lz-graph/\"\n",
    "print(os.listdir(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graph Attention Networks in DGL using SPMV optimization.\n",
    "References\n",
    "----------\n",
    "Paper: https://arxiv.org/abs/1710.10903\n",
    "Author's code: https://github.com/PetarV-/GAT\n",
    "Pytorch implementation: https://github.com/Diego999/pyGAT\n",
    "\"\"\"\n",
    "import dgl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import EdgeSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voyager/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ACCTNO</th>\n",
       "      <th>CUSTOMTYPE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MISSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6214664260258704</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            ACCTNO  CUSTOMTYPE     NAME\n",
       "0   0                 0           0  MISSING\n",
       "1   1  6214664260258704           0      NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_data = '../lz-graph/data/nodes.csv'\n",
    "nodes_data = pd.read_csv(nodes_data,header = 0 ,index_col=0)\n",
    "nodes_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voyager/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TRANSOURCE</th>\n",
       "      <th>ACCTNO</th>\n",
       "      <th>ACCTNO1</th>\n",
       "      <th>TRANAMT</th>\n",
       "      <th>CDFLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327880</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-01-00.09.48.687448</td>\n",
       "      <td>88</td>\n",
       "      <td>101661000111853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338506</td>\n",
       "      <td>316022</td>\n",
       "      <td>2015-07-01-00.00.34.024563</td>\n",
       "      <td>61</td>\n",
       "      <td>78652380011</td>\n",
       "      <td>6214968250550032066</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target                        TIME TRANSOURCE           ACCTNO  \\\n",
       "0  327880       0  2015-07-01-00.09.48.687448         88  101661000111853   \n",
       "1  338506  316022  2015-07-01-00.00.34.024563         61      78652380011   \n",
       "\n",
       "               ACCTNO1  TRANAMT CDFLAG  \n",
       "0                  NaN      0.0      C  \n",
       "1  6214968250550032066  40000.0      D  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_data = '../lz-graph/data/links.csv'\n",
    "links = pd.read_csv(links_data,header = 0 ,index_col=0)\n",
    "links.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TRANSOURCE</th>\n",
       "      <th>ACCTNO</th>\n",
       "      <th>ACCTNO1</th>\n",
       "      <th>TRANAMT</th>\n",
       "      <th>CDFLAG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327880</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-01-00.09.48.687448</td>\n",
       "      <td>88</td>\n",
       "      <td>101661000111853</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.435681e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338506</td>\n",
       "      <td>316022</td>\n",
       "      <td>2015-07-01-00.00.34.024563</td>\n",
       "      <td>61</td>\n",
       "      <td>78652380011</td>\n",
       "      <td>6214968250550032066</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.435680e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target                        TIME TRANSOURCE           ACCTNO  \\\n",
       "0  327880       0  2015-07-01-00.09.48.687448         88  101661000111853   \n",
       "1  338506  316022  2015-07-01-00.00.34.024563         61      78652380011   \n",
       "\n",
       "               ACCTNO1  TRANAMT CDFLAG     timestamp  \n",
       "0                  nan      0.0      C  1.435681e+09  \n",
       "1  6214968250550032066  40000.0      D  1.435680e+09  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "links[\"timestamp\"] = (links[\"TIME\"].str[0:19])\n",
    "#links[\"timestamp\"] = pd.to_datetime(links[\"timestamp\"],format = '%Y-%m-%d-%H.%M.%S' )\n",
    "links[\"timestamp\"]  = links[\"timestamp\"].apply(lambda x : time.mktime(time.strptime(x,'%Y-%m-%d-%H.%M.%S')   )) \n",
    "links[\"ACCTNO\"] = links[\"ACCTNO\"].astype(str)  #\n",
    "links[\"ACCTNO1\"] = links[\"ACCTNO1\"].astype(str) \n",
    "links.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择异常或正常点做标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source          int64\n",
       "target          int64\n",
       "TIME           object\n",
       "TRANSOURCE     object\n",
       "ACCTNO         object\n",
       "ACCTNO1        object\n",
       "TRANAMT       float64\n",
       "CDFLAG         object\n",
       "timestamp     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acctno = \"102561000017549\"\n",
    "links.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TRANSOURCE</th>\n",
       "      <th>ACCTNO</th>\n",
       "      <th>ACCTNO1</th>\n",
       "      <th>TRANAMT</th>\n",
       "      <th>CDFLAG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, target, TIME, TRANSOURCE, ACCTNO, ACCTNO1, TRANAMT, CDFLAG, timestamp]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.loc[(links[\"ACCTNO1\"]== acctno),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.loc[(links[\"ACCTNO\"]==acctno) | (links[\"ACCTNO1\"]==acctno),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "We have 1631199 nodes.\n",
      "We have 2564961 edges.\n",
      "<class 'dgl.graph.DGLGraph'>\n"
     ]
    }
   ],
   "source": [
    "cleans = links.loc[links[\"TRANAMT\"]>1000,:]\n",
    "import torch as th\n",
    "#nodes_id = th.tensor(nodes_data[\"id\"].astype(\"int\").values)\n",
    "def build_graph(nodes,links):\n",
    "    g = dgl.DGLGraph()\n",
    "    # add 34 nodes into the graph; nodes are labeled from 0~33\n",
    "    g.add_nodes(len(nodes))\n",
    "    edge_list = [tuple(x) for x in links[[\"source\",\"target\"]].values]\n",
    "    src, dst = tuple(zip(*edge_list))\n",
    "    print(type(src))\n",
    "    g.add_edges(src,dst)\n",
    "    #g.edata[\"y\"] = links.as_matrix()\n",
    "    return g\n",
    "G = build_graph(nodes = nodes_data,links = cleans)\n",
    "print('We have %d nodes.' % G.number_of_nodes())\n",
    "print('We have %d edges.' % G.number_of_edges())\n",
    "print(type(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voyager/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "customtype = pd.get_dummies(nodes_data[\"CUSTOMTYPE\"].astype(str)).as_matrix()   #convert pandas to pytorch tensor\n",
    "inputs = th.tensor(customtype,dtype = torch.float)   #哑变量  ,,dtype=torch.long  #https://wsonh.com/article/6.html   #nodes的features\n",
    "id0 = nodes_data.loc[nodes_data[\"ACCTNO\"]==\"102561000017549\",\"id\"].values[0]    #来源于数据源，任意取\n",
    "id1 = nodes_data.loc[nodes_data[\"ACCTNO\"]==\"101091000178241\",\"id\"].values[0]    #来源于异常报告，挑选的几个典型的异常点  ，#2015/7/16\n",
    "id2 = nodes_data.loc[nodes_data[\"ACCTNO\"]==\"102192000158598\",\"id\"].values[0]  \n",
    "id3 = nodes_data.loc[nodes_data[\"ACCTNO\"]==\"6214968210550305540\",\"id\"].values[0] #2015/7/16\n",
    "#id3 = nodes_data.loc[nodes_data[\"ACCTNO\"]==\"102191000178651\",\"id\"].values[0]  #暂时，找不到这个异常点\n",
    "\n",
    "labeled_nodes = th.tensor([id0 ,id1, id2 ,id3])  # only the instructor and the president nodes are labeled\n",
    "labels = th.tensor([0,1,1,0])  # their labels are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有问题都要转换成矩阵，并且行数要是node的个数。因此边的属性，可能是多个dataframe，也就是需要tensor的结果来组织，进行计算。3维怎么计算？\n",
    "#多维张量 tensor的计算规则。\n",
    "#基于多维张量的清洗，运算方式。矩阵计算\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # 公式 (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # 公式 (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # 公式 (2) 所需，边上的用户定义函数\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e' : F.leaky_relu(a)}\n",
    "    \n",
    "    #消息传递函数\n",
    "    def message_func(self, edges):                             #属性定义成变量\n",
    "        # 公式 (3), (4)所需，传递消息用的用户定义函数\n",
    "        return {'z' : edges.src['z'], 'e' : edges.data['e']}   #把边属性放进来了,e的结构不确定，但边里面知道来源节点和目标节点信息\n",
    "    #消息累计函数\n",
    "    def reduce_func(self, nodes):                       #可以看作是：数据清理函数，定义*****，打印验证\n",
    "        # 公式 (3), (4)所需, 归约用的用户定义函数         #softmax:标准化，mailbox：邻近节点特征\n",
    "        # 公式 (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)     #边和节点进行了计算，得到一个规范矩阵==》进模型\n",
    "        # 公式 (4)                                       #使用 Softmax 计算每个类别的概率，使用向后传播更新参数。?\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)      #对所有邻节点节点特征求平均并覆盖原本的节点特征===》有点像时间窗口？\n",
    "        return {'h' : h}\n",
    "\n",
    "    def forward(self, h):\n",
    "        # 公式 (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # 公式 (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # 公式 (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多头注意力 (Multi-head attention)\n",
    "\n",
    "神似卷积神经网络里的多通道，GAT 引入了多头注意力来丰富模型的能力和稳定训练的过程。每一个注意力的头都有它自己的参数。如何整合多个注意力机制的输出结果一般有两种方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # 对输出特征维度（第1维）做拼接\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # 用求平均整合多头结果\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个两层的 GAT 模型：\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # 注意输入的维度是 hidden_dim * num_heads 因为多头的结果都被拼接在了\n",
    "        # 一起。 此外输出层只有一个头。\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们使用 DGL 自带的数据模块加载 Cora 数据集。\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import citation_graph as citegrh\n",
    "\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()                     # num_nodes=2708, num_edges=10556\n",
    "    features = torch.FloatTensor(data.features)    #2708 , 1433\n",
    "    labels = torch.LongTensor(data.labels)         #2708  [int]==》目标变量的取值\n",
    "    mask = torch.ByteTensor(data.train_mask)       #2708  [1,0]===>标签？\n",
    "    g = DGLGraph(data.graph)\n",
    "    return g, features, labels, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新加的 准确率 函数、训练集、测试集、验证集\n",
    "# 参考：https://github.com/dmlc/dgl/blob/master/examples/pytorch/gat/train.py\n",
    "def accuracy(logits, labels):\n",
    "    _, indices = torch.max(logits, dim=1)\n",
    "    correct = torch.sum(indices == labels)     # indices 预测值  == label便签。correct个数\n",
    "    return correct.item() * 1.0 / len(labels)  #预测正确的个数/总标签个数\n",
    "\n",
    "def evaluate(model, features, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():                      #再次验证\n",
    "        logits = model(features)\n",
    "        logits = logits[labels]\n",
    "        return accuracy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voyager/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n",
      "/home/voyager/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/voyager/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 0.6624 | Time(s) nan| TrainAcc 0.2500\n",
      "Epoch 00001 | Loss 0.6614 | Time(s) nan| TrainAcc 0.2500\n",
      "Epoch 00002 | Loss 0.6604 | Time(s) nan| TrainAcc 0.5000\n",
      "Epoch 00003 | Loss 0.6594 | Time(s) 40.0679| TrainAcc 0.5000\n",
      "Epoch 00004 | Loss 0.6585 | Time(s) 40.1332| TrainAcc 0.5000\n",
      "Epoch 00005 | Loss 0.6575 | Time(s) 40.0968| TrainAcc 0.5000\n",
      "Epoch 00006 | Loss 0.6565 | Time(s) 40.0323| TrainAcc 0.7500\n",
      "Epoch 00007 | Loss 0.6555 | Time(s) 40.0267| TrainAcc 0.7500\n",
      "Epoch 00008 | Loss 0.6545 | Time(s) 40.0211| TrainAcc 0.7500\n",
      "Epoch 00009 | Loss 0.6536 | Time(s) 40.0029| TrainAcc 0.7500\n",
      "Epoch 00010 | Loss 0.6526 | Time(s) 40.0304| TrainAcc 0.7500\n",
      "Epoch 00011 | Loss 0.6516 | Time(s) 40.0118| TrainAcc 0.7500\n",
      "Epoch 00012 | Loss 0.6506 | Time(s) 40.0165| TrainAcc 0.7500\n",
      "Epoch 00013 | Loss 0.6497 | Time(s) 40.0725| TrainAcc 0.7500\n",
      "Epoch 00014 | Loss 0.6487 | Time(s) 40.0956| TrainAcc 0.7500\n",
      "Epoch 00015 | Loss 0.6477 | Time(s) 40.1261| TrainAcc 0.7500\n",
      "Epoch 00016 | Loss 0.6467 | Time(s) 40.1421| TrainAcc 0.7500\n",
      "Epoch 00017 | Loss 0.6457 | Time(s) 40.1645| TrainAcc 0.7500\n",
      "Epoch 00018 | Loss 0.6447 | Time(s) 40.1818| TrainAcc 0.7500\n",
      "Epoch 00019 | Loss 0.6437 | Time(s) 40.1817| TrainAcc 0.7500\n",
      "Epoch 00020 | Loss 0.6428 | Time(s) 40.1814| TrainAcc 0.7500\n",
      "Epoch 00021 | Loss 0.6418 | Time(s) 40.1914| TrainAcc 0.7500\n",
      "Epoch 00022 | Loss 0.6407 | Time(s) 40.2025| TrainAcc 0.7500\n",
      "Epoch 00023 | Loss 0.6398 | Time(s) 40.2123| TrainAcc 0.7500\n",
      "Epoch 00024 | Loss 0.6387 | Time(s) 40.2256| TrainAcc 0.7500\n",
      "Epoch 00025 | Loss 0.6377 | Time(s) 40.2261| TrainAcc 0.7500\n",
      "Epoch 00026 | Loss 0.6367 | Time(s) 40.2325| TrainAcc 0.7500\n",
      "Epoch 00027 | Loss 0.6357 | Time(s) 40.2234| TrainAcc 0.7500\n",
      "Epoch 00028 | Loss 0.6347 | Time(s) 40.2301| TrainAcc 0.7500\n",
      "Epoch 00029 | Loss 0.6337 | Time(s) 40.2408| TrainAcc 0.7500\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 创建模型\n",
    "net = GAT(G, \n",
    "          in_dim=4, \n",
    "          hidden_dim=3, \n",
    "          out_dim=2, \n",
    "          num_heads=3)\n",
    "#print(net)\n",
    "\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# 主流程\n",
    "dur = []\n",
    "for epoch in range(30):\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    logits = net(inputs)   #预测值\n",
    "    logp = F.log_softmax(logits, 1)  #标准化 ==>值域0,1==》概率\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "\n",
    "    optimizer.zero_grad()  # 清零所有参数（parameter）的梯度缓存\n",
    "    loss.backward()        #loss.backward()来反向传播权重\n",
    "    optimizer.step()       # 更新参数\n",
    "    train_acc = accuracy(logp[labeled_nodes], labels)   #===mask\n",
    "    \n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f}| TrainAcc {:.4f}\".format(\n",
    "            epoch, loss.item(), np.mean(dur),train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(net, inputs, labels)\n",
    "print(\"Test Accuracy {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = torch.max(logp, dim=1)   #  预测值\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1451686)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp[labeled_nodes]\n",
    "_, indices = torch.max(logp[labeled_nodes], dim=1)   #  预测值\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
