{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch GAE (Graph Auto-Encoder)\n",
    "\n",
    "## Dataset\n",
    "\n",
    "For PyG dataset, refer to [Creating your own datasets](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html) and [Data handling of graphs](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#data-handling-of-graphs).  \n",
    "\n",
    "We only need ```data.x``` and ```data.edge_index``` for original GAE.  \n",
    "\n",
    "For bank transfer anomaly detection, we may need extra field - ```data.edge_attr```, so the edges are weighted.  \n",
    "Also, we wish to deal with directed edges.  \n",
    "I guess all these info could be merged into adjacency matrix.  \n",
    "\n",
    "[GCNConv.forward](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv.forward)  \n",
    "Since GCNConv (encoder of GAE) supports ```edge_weight```, ```data.edge_attr``` could store amount as weight and be fed into edge_weight.  \n",
    "\n",
    "For node feature, we only have account custom type - 0-3.  \n",
    "For edge features, we have:  \n",
    "  1. amount - total transfer amount during an given period.  \n",
    "  2. count - total transfer count  \n",
    "  3. source - transfer channel  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "# consts\n",
    "root_path = '/home/voyager/project/lz-graph/data/'\n",
    "\n",
    "node_df = pd.read_csv(os.path.join(root_path, 'nodes.csv'))\n",
    "type_list = node_df['CUSTOMTYPE']\n",
    "\n",
    "x = torch.tensor([[value] for value in type_list], dtype=torch.float)\n",
    "\n",
    "link_df = pd.read_csv(os.path.join(root_path, 'stat_links.csv'))\n",
    "source_list = link_df['source']\n",
    "target_list = link_df['target']\n",
    "amount_list = link_df['sum'] # total transfer amount\n",
    "\n",
    "edge_index = torch.tensor([source_list, target_list], dtype=torch.long)\n",
    "edge_attr = torch.tensor([[amount] for amount in amount_list], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkX G - nodes: 1631199, edges: 2770964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# push graph into networkx\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(len(type_list)))\n",
    "G.add_edges_from([(source_list[i], target_list[i]) for i in range(len(source_list))])\n",
    "\n",
    "print('networkX G - nodes: {}, edges: {}\\n'.format(G.number_of_nodes(), G.number_of_edges()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1631199 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/1631199 [00:03<1666:27:21,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/1631199 [00:03<1196:06:13,  2.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/1631199 [00:05<1107:41:42,  2.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/1631199 [00:08<983:03:42,  2.17s/it] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/1631199 [00:09<716:33:16,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/1631199 [00:09<527:46:32,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 10/1631199 [00:11<459:20:59,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 12/1631199 [00:11<334:40:04,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 13/1631199 [00:13<502:25:58,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 14/1631199 [00:16<769:14:02,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/1631199 [00:16<566:43:35,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 20/1631199 [00:18<451:21:36,  1.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 21/1631199 [00:18<344:20:22,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 22/1631199 [00:19<267:05:51,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 23/1631199 [00:19<213:14:54,  2.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 24/1631199 [00:19<175:48:26,  2.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/1631199 [00:21<168:04:20,  2.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9383247471f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfs_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbfs_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/networkx/algorithms/traversal/breadth_first_search.py\u001b[0m in \u001b[0;36mbfs_edges\u001b[0;34m(G, source, reverse, depth_limit)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuccessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# TODO In Python 3.3+, this should be `yield from ...`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgeneric_bfs_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccessors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/networkx/algorithms/traversal/breadth_first_search.py\u001b[0m in \u001b[0;36mgeneric_bfs_edges\u001b[0;34m(G, source, neighbors, depth_limit)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mvisited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdepth_now\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_now\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pull out subgraph of each node\n",
    "\n",
    "# consts\n",
    "bfs_depth = 3\n",
    "\n",
    "for node in tqdm(range(len(type_list))):\n",
    "    edges = list(nx.bfs_edges(G, node, depth_limit=bfs_depth))\n",
    "    nodes = [node] + [v for u, v in edges]\n",
    "\n",
    "print('bfs (depth {}) subgraph for node 500 - nodes: {}, edges: {}'.format(bfs_depth, len(list(nodes)), len(list(edges))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "networkX G - nodes: 1631199, edges: 2770964\n",
      "\n",
      "bfs subgraph for node 1 - nodes: 822252, edges: 0\n",
      "Done!\n",
      "PyG data - Data(edge_attr=[2770964, 1], edge_index=[2, 2770964], x=[1631199, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# consts\n",
    "\n",
    "class TranStatDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(TranStatDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['nodes.csv', 'stat_links.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # we don't download\n",
    "        pass\n",
    "\n",
    "    def process(self):        \n",
    "        # Read data into huge `Data` list.\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        data_list = [data]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        \n",
    "dataset = TranStatDataset(root_path, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "print('PyG data - {}'.format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAE Model\n",
    "\n",
    "[Variational Graph Auto-Encoders](https://arxiv.org/pdf/1611.07308.pdf)\n",
    "\n",
    "GAE and VGAE are originally designed for link prediction.  \n",
    "  \n",
    "Given an undirected, unweighted graph G(V, E), introduce an adjacency matrix A and node feature matrix X.  \n",
    "The problem is to reconstruct adjacency matrix A*.  \n",
    "  \n",
    "In practice, we could use GAE/VGAEs to reconstruct A* (from actual A and X) to predict transfers between accounts.  \n",
    "Predicted edges differ from actual are considered anomalies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 2478GB. Buy new RAM! at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-769caeb82629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/torch_geometric/nn/models/autoencoder.py\u001b[0m in \u001b[0;36msplit_edges\u001b[0;34m(self, data, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Negative edges.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mneg_adj_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mneg_adj_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_adj_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mneg_adj_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 2478GB. Buy new RAM! at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "\n",
    "# consts\n",
    "MODEL_TYPE = 'GAE' # ['GAE', 'VGAE']\n",
    "\n",
    "# vars\n",
    "kwargs = {'GAE': GAE, 'VGAE': VGAE}\n",
    "channels = 16 # embedding dimentions\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        if MODEL_TYPE in ['GAE']:\n",
    "            self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        elif MODEL_TYPE in ['VGAE']:\n",
    "            self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "            self.conv_logvar = GCNConv(\n",
    "                2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        if MODEL_TYPE in ['GAE']:\n",
    "            return self.conv2(x, edge_index)\n",
    "        elif MODEL_TYPE in ['VGAE']:\n",
    "            return self.conv_mu(x, edge_index), self.conv_logvar(x, edge_index)\n",
    "        \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = kwargs[MODEL_TYPE](Encoder(dataset.num_features, channels)).to(device)\n",
    "\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = model.split_edges(data)\n",
    "x, edge_index = data.x.to(device), data.edge_index.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "EPOCHS = 200\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model.encode(x, edge_index)\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    if MODEL_TYPE in ['VGAE']:\n",
    "        loss = loss + 0.001 * model.kl_loss()\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, edge_index)\n",
    "        \n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    train()\n",
    "    auc, ap = test(data.val_pos_edge_index, data.val_neg_edge_index)\n",
    "    \n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge,chrome=1\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width\" />\n",
      "    <title>moop-ui</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/bootstrap4.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/open-iconic-bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/main.css\">\n",
      "  <link rel=\"shortcut icon\" href=\"/favicon.png\"><link href=\"/css\\index.css\" rel=\"stylesheet\"></head>\n",
      "\n",
      "  <body>\n",
      "    <div id=\"ice-container\"></div>\n",
      "    <script src=\"/static/js/jquery.slim.min.js\" ></script>\n",
      "    <script src=\"/static/js/popper.min.js\" ></script>\n",
      "    <script src=\"/static/js/bootstrap.min.js\" ></script>\n",
      "  <script type=\"text/javascript\" src=\"/js\\index.js\"></script></body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('https://office.orientsoft.cn:8443')\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
