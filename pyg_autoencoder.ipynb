{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch GAE (Graph Auto-Encoder)\n",
    "\n",
    "## Dataset\n",
    "\n",
    "For PyG dataset, refer to [Creating your own datasets](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html) and [Data handling of graphs](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#data-handling-of-graphs).  \n",
    "\n",
    "We only need ```data.x``` and ```data.edge_index``` for original GAE.  \n",
    "\n",
    "For bank transfer anomaly detection, we may need extra field - ```data.edge_attr```, so the edges are weighted.  \n",
    "Also, we wish to deal with directed edges.  \n",
    "I guess all these info could be merged into adjacency matrix.  \n",
    "\n",
    "[GCNConv.forward](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv.forward)  \n",
    "Since GCNConv (encoder of GAE) supports ```edge_weight```, ```data.edge_attr``` could store amount as weight and be fed into edge_weight.  \n",
    "\n",
    "For node feature, we only have account custom type - 0-3.  \n",
    "For edge features, we have:  \n",
    "  1. amount - total transfer amount during an given period.  \n",
    "  2. count - total transfer count  \n",
    "  3. source - transfer channel  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "# consts\n",
    "root_path = '/home/xd/data/lz_trans/'\n",
    "\n",
    "node_df = pd.read_csv(os.path.join(root_path, 'extra_type.csv'))\n",
    "type_list = node_df['type']\n",
    "\n",
    "# x = torch.tensor([[value] for value in type_list], dtype=torch.float)\n",
    "\n",
    "link_df = pd.read_csv(os.path.join(root_path, 'extra_link.csv'))\n",
    "source_list = link_df['source']\n",
    "target_list = link_df['target']\n",
    "amount_list = link_df['amount'] # total transfer amount\n",
    "\n",
    "# edge_index = torch.tensor([source_list, target_list], dtype=torch.long)\n",
    "# edge_attr = torch.tensor([[amount] for amount in amount_list], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2480730905a426caf250864cab4bbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2770964), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "networkX G - nodes: 2624591, edges: 2770964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# push graph into networkx\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(len(type_list)))\n",
    "G.add_edges_from([(source_list[i], target_list[i]) for i in tqdm(range(len(source_list)))])\n",
    "\n",
    "print('networkX G - nodes: {}, edges: {}\\n'.format(\n",
    "    G.number_of_nodes(),\n",
    "    G.number_of_edges()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb95ba52f9f40798654735134b12e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2624591), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pull out subgraph of each node\n",
    "\n",
    "# consts\n",
    "bfs_depth = 5\n",
    "workers = 8\n",
    "\n",
    "def pull_subgraph(node, depth):\n",
    "    edges = list(nx.bfs_edges(G, node, depth_limit=depth))\n",
    "    nodes = [node] + [v for u, v in edges]\n",
    "    \n",
    "    '''\n",
    "    if (len(edges) != len(nodes) - 1) or (len(edges) > 40000):\n",
    "        print('bfs (depth {}) subgraph for node {} - nodes: {}, edges: {}'.format(\n",
    "            bfs_depth,\n",
    "            node,\n",
    "            len(nodes),\n",
    "            len(edges)\n",
    "        ))\n",
    "    '''\n",
    "    \n",
    "    result = {\n",
    "        'edges': edges,\n",
    "        'nodes': nodes\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def pull_all_subgraph():\n",
    "    # create pool\n",
    "    with mp.Pool(processes=8) as pool:\n",
    "        results = [pool.apply_async(pull_subgraph, (node, bfs_depth)) for node in tqdm(range(len(type_list)))]\n",
    "        results = [result.get() for result in tqdm(results)]\n",
    "\n",
    "        print(len(results))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    pull_all_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 487/1631199 [00:00<05:35, 4864.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1631199/1631199 [00:53<00:00, 30407.86it/s]\n",
      " 76%|███████▌  | 1239223/1631199 [4:13:16<136:31:11,  1.25s/it]"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8759987b3df4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got end of file during message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Since pulling out subgraph is very slow\n",
    "# we are using parallel machines to speed up\n",
    "\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "# consts\n",
    "bfs_depth = 3\n",
    "\n",
    "class QueueManager(BaseManager): pass\n",
    "QueueManager.register('get_task_queue')\n",
    "QueueManager.register('get_result_queue')\n",
    "QueueManager.register('get_init_dict')\n",
    "\n",
    "manager = QueueManager(address=('127.0.0.1', 50000), authkey=b'asdfjkl;')\n",
    "\n",
    "manager.connect()\n",
    "task_queue = manager.get_task_queue()\n",
    "result_queue = manager.get_result_queue()\n",
    "\n",
    "init_data = manager.get_init_dict()\n",
    "print(init_data.get('node_count'))\n",
    "\n",
    "for node in tqdm(range(len(type_list))):\n",
    "    task = {\n",
    "        'node': node,\n",
    "        'bfs_depth': bfs_depth\n",
    "    }\n",
    "    \n",
    "    task_queue.put(task)\n",
    "\n",
    "results = []\n",
    "for node in tqdm(range(len(type_list))):\n",
    "    result = result_queue.get()\n",
    "    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyG data - Data(edge_attr=[2770964, 1], edge_index=[2, 2770964], x=[1631199, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# consts\n",
    "\n",
    "class TranStatDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(TranStatDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['nodes.csv', 'stat_links.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # we don't download\n",
    "        pass\n",
    "\n",
    "    def process(self):        \n",
    "        # Read data into huge `Data` list.\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        data_list = [data]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        \n",
    "dataset = TranStatDataset(root_path, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "print('PyG data - {}'.format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAE Model\n",
    "\n",
    "[Variational Graph Auto-Encoders](https://arxiv.org/pdf/1611.07308.pdf)\n",
    "\n",
    "GAE and VGAE are originally designed for link prediction.  \n",
    "  \n",
    "Given an undirected, unweighted graph G(V, E), introduce an adjacency matrix A and node feature matrix X.  \n",
    "The problem is to reconstruct adjacency matrix A*.  \n",
    "  \n",
    "In practice, we could use GAE/VGAEs to reconstruct A* (from actual A and X) to predict transfers between accounts.  \n",
    "Predicted edges differ from actual are considered anomalies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 2478GB. Buy new RAM! at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-769caeb82629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_pytorch/lib/python3.6/site-packages/torch_geometric/nn/models/autoencoder.py\u001b[0m in \u001b[0;36msplit_edges\u001b[0;34m(self, data, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Negative edges.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mneg_adj_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mneg_adj_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_adj_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mneg_adj_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 2478GB. Buy new RAM! at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "\n",
    "# consts\n",
    "MODEL_TYPE = 'GAE' # ['GAE', 'VGAE']\n",
    "\n",
    "# vars\n",
    "kwargs = {'GAE': GAE, 'VGAE': VGAE}\n",
    "channels = 16 # embedding dimentions\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        if MODEL_TYPE in ['GAE']:\n",
    "            self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        elif MODEL_TYPE in ['VGAE']:\n",
    "            self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "            self.conv_logvar = GCNConv(\n",
    "                2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        if MODEL_TYPE in ['GAE']:\n",
    "            return self.conv2(x, edge_index)\n",
    "        elif MODEL_TYPE in ['VGAE']:\n",
    "            return self.conv_mu(x, edge_index), self.conv_logvar(x, edge_index)\n",
    "        \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = kwargs[MODEL_TYPE](Encoder(dataset.num_features, channels)).to(device)\n",
    "\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = model.split_edges(data)\n",
    "x, edge_index = data.x.to(device), data.edge_index.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "EPOCHS = 200\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model.encode(x, edge_index)\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    if MODEL_TYPE in ['VGAE']:\n",
    "        loss = loss + 0.001 * model.kl_loss()\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, edge_index)\n",
    "        \n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    train()\n",
    "    auc, ap = test(data.val_pos_edge_index, data.val_neg_edge_index)\n",
    "    \n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge,chrome=1\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width\" />\n",
      "    <title>moop-ui</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/bootstrap4.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/open-iconic-bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/css/main.css\">\n",
      "  <link rel=\"shortcut icon\" href=\"/favicon.png\"><link href=\"/css\\index.css\" rel=\"stylesheet\"></head>\n",
      "\n",
      "  <body>\n",
      "    <div id=\"ice-container\"></div>\n",
      "    <script src=\"/static/js/jquery.slim.min.js\" ></script>\n",
      "    <script src=\"/static/js/popper.min.js\" ></script>\n",
      "    <script src=\"/static/js/bootstrap.min.js\" ></script>\n",
      "  <script type=\"text/javascript\" src=\"/js\\index.js\"></script></body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('https://office.orientsoft.cn:8443')\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
